{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHIQiT1yFI3V",
    "tags": []
   },
   "source": [
    "# Dataset Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5bGtr-uFI3V",
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDG1Yk_CFI3W",
    "tags": []
   },
   "source": [
    "# Global Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PvCormKGFI3W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sklearn\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# set matplotlib to display graphics in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDuqcj9rFI3X",
    "tags": []
   },
   "source": [
    "# Dataset Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTBLALpUFI3X"
   },
   "source": [
    "This section imports the diabetes dataset provided for the assignment. The dataset is saved in csv format in the same folder as the project notebook. The file is imported into the project as a pandas dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zKab0oS5FI3X",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records imported: 5000\n"
     ]
    }
   ],
   "source": [
    "# import dataset from csv\n",
    "ml_dataset = pd.read_csv('./Synthetic_Data_For_Students.csv')\n",
    "\n",
    "# confirm number of imported records matches expected size\n",
    "print(\"Number of records imported: \" + str(len(ml_dataset.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCTBWw8PFI3X",
    "tags": []
   },
   "source": [
    "# Dataset Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a_Qs90pFI3X",
    "tags": []
   },
   "source": [
    "## Display Dataset Summary Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7wwbrI7_FI3X",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 36 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   SettlementValue             4894 non-null   float64\n",
      " 1   AccidentType                4878 non-null   object \n",
      " 2   Injury_Prognosis            4844 non-null   object \n",
      " 3   SpecialHealthExpenses       4870 non-null   float64\n",
      " 4   SpecialReduction            4879 non-null   float64\n",
      " 5   SpecialOverage              4883 non-null   float64\n",
      " 6   GeneralRest                 4872 non-null   float64\n",
      " 7   SpecialAdditionalInjury     4866 non-null   float64\n",
      " 8   SpecialEarningsLoss         4872 non-null   float64\n",
      " 9   SpecialUsageLoss            4870 non-null   float64\n",
      " 10  SpecialMedications          4870 non-null   float64\n",
      " 11  SpecialAssetDamage          4889 non-null   float64\n",
      " 12  SpecialRehabilitation       4884 non-null   float64\n",
      " 13  SpecialFixes                4879 non-null   float64\n",
      " 14  GeneralFixed                4879 non-null   float64\n",
      " 15  GeneralUplift               4863 non-null   float64\n",
      " 16  SpecialLoanerVehicle        4861 non-null   float64\n",
      " 17  SpecialTripCosts            4885 non-null   float64\n",
      " 18  SpecialJourneyExpenses      4853 non-null   float64\n",
      " 19  SpecialTherapy              4868 non-null   float64\n",
      " 20  Exceptional_Circumstances   4891 non-null   object \n",
      " 21  Minor_Psychological_Injury  4881 non-null   object \n",
      " 22  Dominant injury             4890 non-null   object \n",
      " 23  Whiplash                    4870 non-null   object \n",
      " 24  Vehicle Type                4874 non-null   object \n",
      " 25  Weather Conditions          4886 non-null   object \n",
      " 26  Accident Date               4862 non-null   object \n",
      " 27  Claim Date                  4891 non-null   object \n",
      " 28  Vehicle Age                 4874 non-null   float64\n",
      " 29  Driver Age                  4871 non-null   float64\n",
      " 30  Number of Passengers        4878 non-null   float64\n",
      " 31  Accident Description        4880 non-null   object \n",
      " 32  Injury Description          4881 non-null   object \n",
      " 33  Police Report Filed         5000 non-null   object \n",
      " 34  Witness Present             5000 non-null   object \n",
      " 35  Gender                      5000 non-null   object \n",
      "dtypes: float64(21), object(15)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "ml_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are null values in multiple columns, these will need to be handled appropriately. Discussion with the client has identified that null values in the settlement column indicate unsettled claims, so these should not be used in model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zRlJuETFI3X"
   },
   "source": [
    "## Display Column Value Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkniW8-eFI3X",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "SettlementValue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialHealthExpenses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialReduction",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialOverage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GeneralRest",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialAdditionalInjury",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialEarningsLoss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialUsageLoss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialMedications",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialAssetDamage",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialRehabilitation",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialFixes",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GeneralFixed",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GeneralUplift",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialLoanerVehicle",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialTripCosts",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialJourneyExpenses",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "SpecialTherapy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Vehicle Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Driver Age",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Number of Passengers",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "89c72882-66e7-4d8e-926c-6add1f1e83a3",
       "rows": [
        [
         "count",
         "4894.0",
         "4870.0",
         "4879.0",
         "4883.0",
         "4872.0",
         "4866.0",
         "4872.0",
         "4870.0",
         "4870.0",
         "4889.0",
         "4884.0",
         "4879.0",
         "4879.0",
         "4863.0",
         "4861.0",
         "4885.0",
         "4853.0",
         "4868.0",
         "4874.0",
         "4871.0",
         "4878.0"
        ],
        [
         "mean",
         "1218.0106845116468",
         "3.61170431211499",
         "0.0",
         "13.363579766536965",
         "463.3053858784893",
         "0.28357994245787094",
         "52.191114532019704",
         "9.1088295687885",
         "0.10969815195071869",
         "33.46076089179792",
         "0.019696969696969695",
         "3.9422094691535152",
         "687.5097356015577",
         "10.407464528069093",
         "7.719720222176506",
         "1.9598807574206756",
         "11.63912013187719",
         "183.6002855382087",
         "9.508617152236356",
         "48.789160336686514",
         "2.482369823698237"
        ],
        [
         "std",
         "858.866308978639",
         "85.04784481304176",
         "0.0",
         "84.22361157774601",
         "766.1876694792307",
         "12.98807495613841",
         "392.9091298018358",
         "65.50518146367304",
         "1.3899163199709317",
         "282.6925292094226",
         "0.628007839367157",
         "116.33505347535609",
         "399.36127850388465",
         "50.165743101862645",
         "141.15565778900833",
         "13.11741944378963",
         "49.086923719917806",
         "223.88578002915003",
         "5.727625354171125",
         "17.81972505858056",
         "1.1099105994730596"
        ],
        [
         "min",
         "240.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "240.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "18.0",
         "1.0"
        ],
        [
         "25%",
         "669.14",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "495.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "4.0",
         "33.0",
         "1.0"
        ],
        [
         "50%",
         "988.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "520.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "50.0",
         "10.0",
         "49.0",
         "2.0"
        ],
        [
         "75%",
         "1510.0",
         "0.0",
         "0.0",
         "0.0",
         "906.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "895.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "350.0",
         "14.0",
         "64.0",
         "3.0"
        ],
        [
         "max",
         "7862.9",
         "3024.0",
         "0.0",
         "1250.0",
         "3912.64",
         "889.0",
         "7735.58",
         "1050.0",
         "30.25",
         "6070.0",
         "21.2",
         "4000.0",
         "4345.0",
         "1430.0",
         "4408.16",
         "254.2",
         "880.0",
         "1225.0",
         "19.0",
         "79.0",
         "4.0"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SettlementValue</th>\n",
       "      <th>SpecialHealthExpenses</th>\n",
       "      <th>SpecialReduction</th>\n",
       "      <th>SpecialOverage</th>\n",
       "      <th>GeneralRest</th>\n",
       "      <th>SpecialAdditionalInjury</th>\n",
       "      <th>SpecialEarningsLoss</th>\n",
       "      <th>SpecialUsageLoss</th>\n",
       "      <th>SpecialMedications</th>\n",
       "      <th>SpecialAssetDamage</th>\n",
       "      <th>...</th>\n",
       "      <th>SpecialFixes</th>\n",
       "      <th>GeneralFixed</th>\n",
       "      <th>GeneralUplift</th>\n",
       "      <th>SpecialLoanerVehicle</th>\n",
       "      <th>SpecialTripCosts</th>\n",
       "      <th>SpecialJourneyExpenses</th>\n",
       "      <th>SpecialTherapy</th>\n",
       "      <th>Vehicle Age</th>\n",
       "      <th>Driver Age</th>\n",
       "      <th>Number of Passengers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4894.000000</td>\n",
       "      <td>4870.000000</td>\n",
       "      <td>4879.0</td>\n",
       "      <td>4883.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4866.000000</td>\n",
       "      <td>4872.000000</td>\n",
       "      <td>4870.000000</td>\n",
       "      <td>4870.000000</td>\n",
       "      <td>4889.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4879.000000</td>\n",
       "      <td>4879.000000</td>\n",
       "      <td>4863.000000</td>\n",
       "      <td>4861.000000</td>\n",
       "      <td>4885.000000</td>\n",
       "      <td>4853.000000</td>\n",
       "      <td>4868.000000</td>\n",
       "      <td>4874.000000</td>\n",
       "      <td>4871.000000</td>\n",
       "      <td>4878.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1218.010685</td>\n",
       "      <td>3.611704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.363580</td>\n",
       "      <td>463.305386</td>\n",
       "      <td>0.283580</td>\n",
       "      <td>52.191115</td>\n",
       "      <td>9.108830</td>\n",
       "      <td>0.109698</td>\n",
       "      <td>33.460761</td>\n",
       "      <td>...</td>\n",
       "      <td>3.942209</td>\n",
       "      <td>687.509736</td>\n",
       "      <td>10.407465</td>\n",
       "      <td>7.719720</td>\n",
       "      <td>1.959881</td>\n",
       "      <td>11.639120</td>\n",
       "      <td>183.600286</td>\n",
       "      <td>9.508617</td>\n",
       "      <td>48.789160</td>\n",
       "      <td>2.482370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>858.866309</td>\n",
       "      <td>85.047845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.223612</td>\n",
       "      <td>766.187669</td>\n",
       "      <td>12.988075</td>\n",
       "      <td>392.909130</td>\n",
       "      <td>65.505181</td>\n",
       "      <td>1.389916</td>\n",
       "      <td>282.692529</td>\n",
       "      <td>...</td>\n",
       "      <td>116.335053</td>\n",
       "      <td>399.361279</td>\n",
       "      <td>50.165743</td>\n",
       "      <td>141.155658</td>\n",
       "      <td>13.117419</td>\n",
       "      <td>49.086924</td>\n",
       "      <td>223.885780</td>\n",
       "      <td>5.727625</td>\n",
       "      <td>17.819725</td>\n",
       "      <td>1.109911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>669.140000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>495.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>988.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1510.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>906.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>895.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7862.900000</td>\n",
       "      <td>3024.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1250.000000</td>\n",
       "      <td>3912.640000</td>\n",
       "      <td>889.000000</td>\n",
       "      <td>7735.580000</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>30.250000</td>\n",
       "      <td>6070.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4345.000000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>4408.160000</td>\n",
       "      <td>254.200000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>1225.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SettlementValue  SpecialHealthExpenses  SpecialReduction  \\\n",
       "count      4894.000000            4870.000000            4879.0   \n",
       "mean       1218.010685               3.611704               0.0   \n",
       "std         858.866309              85.047845               0.0   \n",
       "min         240.000000               0.000000               0.0   \n",
       "25%         669.140000               0.000000               0.0   \n",
       "50%         988.000000               0.000000               0.0   \n",
       "75%        1510.000000               0.000000               0.0   \n",
       "max        7862.900000            3024.000000               0.0   \n",
       "\n",
       "       SpecialOverage  GeneralRest  SpecialAdditionalInjury  \\\n",
       "count     4883.000000  4872.000000              4866.000000   \n",
       "mean        13.363580   463.305386                 0.283580   \n",
       "std         84.223612   766.187669                12.988075   \n",
       "min          0.000000     0.000000                 0.000000   \n",
       "25%          0.000000     0.000000                 0.000000   \n",
       "50%          0.000000     0.000000                 0.000000   \n",
       "75%          0.000000   906.000000                 0.000000   \n",
       "max       1250.000000  3912.640000               889.000000   \n",
       "\n",
       "       SpecialEarningsLoss  SpecialUsageLoss  SpecialMedications  \\\n",
       "count          4872.000000       4870.000000         4870.000000   \n",
       "mean             52.191115          9.108830            0.109698   \n",
       "std             392.909130         65.505181            1.389916   \n",
       "min               0.000000          0.000000            0.000000   \n",
       "25%               0.000000          0.000000            0.000000   \n",
       "50%               0.000000          0.000000            0.000000   \n",
       "75%               0.000000          0.000000            0.000000   \n",
       "max            7735.580000       1050.000000           30.250000   \n",
       "\n",
       "       SpecialAssetDamage  ...  SpecialFixes  GeneralFixed  GeneralUplift  \\\n",
       "count         4889.000000  ...   4879.000000   4879.000000    4863.000000   \n",
       "mean            33.460761  ...      3.942209    687.509736      10.407465   \n",
       "std            282.692529  ...    116.335053    399.361279      50.165743   \n",
       "min              0.000000  ...      0.000000    240.000000       0.000000   \n",
       "25%              0.000000  ...      0.000000    495.000000       0.000000   \n",
       "50%              0.000000  ...      0.000000    520.000000       0.000000   \n",
       "75%              0.000000  ...      0.000000    895.000000       0.000000   \n",
       "max           6070.000000  ...   4000.000000   4345.000000    1430.000000   \n",
       "\n",
       "       SpecialLoanerVehicle  SpecialTripCosts  SpecialJourneyExpenses  \\\n",
       "count           4861.000000       4885.000000             4853.000000   \n",
       "mean               7.719720          1.959881               11.639120   \n",
       "std              141.155658         13.117419               49.086924   \n",
       "min                0.000000          0.000000                0.000000   \n",
       "25%                0.000000          0.000000                0.000000   \n",
       "50%                0.000000          0.000000                0.000000   \n",
       "75%                0.000000          0.000000                0.000000   \n",
       "max             4408.160000        254.200000              880.000000   \n",
       "\n",
       "       SpecialTherapy  Vehicle Age   Driver Age  Number of Passengers  \n",
       "count     4868.000000  4874.000000  4871.000000           4878.000000  \n",
       "mean       183.600286     9.508617    48.789160              2.482370  \n",
       "std        223.885780     5.727625    17.819725              1.109911  \n",
       "min          0.000000     0.000000    18.000000              1.000000  \n",
       "25%          0.000000     4.000000    33.000000              1.000000  \n",
       "50%         50.000000    10.000000    49.000000              2.000000  \n",
       "75%        350.000000    14.000000    64.000000              3.000000  \n",
       "max       1225.000000    19.000000    79.000000              4.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display summary statistics for numerical columns\n",
    "ml_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show total values for each numerical column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column - count of non-zero - sum of values - mean values\n",
      "SettlementValue - 4894 - 5960944.289999999 - 1218.0106845116468\n",
      "SpecialHealthExpenses - 16 - 17589.0 - 1099.3125\n",
      "SpecialReduction - 0 - 0.0 - nan\n",
      "SpecialOverage - 160 - 65254.36 - 407.83975\n",
      "GeneralRest - 1671 - 2257223.84 - 1350.8221663674447\n",
      "SpecialAdditionalInjury - 9 - 1379.9 - 153.32222222222222\n",
      "SpecialEarningsLoss - 296 - 254275.11 - 859.0375337837837\n",
      "SpecialUsageLoss - 244 - 44360.0 - 181.80327868852459\n",
      "SpecialMedications - 38 - 534.23 - 14.058684210526316\n",
      "SpecialAssetDamage - 472 - 163589.66 - 346.5882627118644\n",
      "SpecialRehabilitation - 5 - 96.19999999999999 - 19.24\n",
      "SpecialFixes - 10 - 19234.04 - 1923.404\n",
      "GeneralFixed - 4879 - 3354360.0 - 687.5097356015577\n",
      "GeneralUplift - 311 - 50611.5 - 162.7379421221865\n",
      "SpecialLoanerVehicle - 69 - 37525.56 - 543.8486956521739\n",
      "SpecialTripCosts - 255 - 9574.0175 - 37.54516666666667\n",
      "SpecialJourneyExpenses - 1003 - 56484.65 - 56.315702891326026\n",
      "SpecialTherapy - 2711 - 893766.1900000001 - 329.681368498709\n",
      "Vehicle Age - 4649 - 46345.0 - 9.96881049688105\n",
      "Driver Age - 4871 - 237652.0 - 48.789160336686514\n",
      "Number of Passengers - 4878 - 12109.0 - 2.482369823698237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BB\\AppData\\Local\\Temp\\ipykernel_26572\\2333528509.py:4: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  print(column + \" - \" + str(ml_dataset[ml_dataset[column] != 0][column].count()) + \" - \" + str(ml_dataset[column].sum()) + \" - \" + str((ml_dataset[column].sum() / ml_dataset[ml_dataset[column] != 0][column].count())))\n"
     ]
    }
   ],
   "source": [
    "# for each numerical column, diplay the count of non-zero values\n",
    "print(\"column - count of non-zero - sum of values - mean values (excluding zero rows)\")\n",
    "for column in ml_dataset.select_dtypes(include=[np.number]):\n",
    "    print(column + \" - \" + str(ml_dataset[ml_dataset[column] != 0][column].count()) + \" - \" + str(ml_dataset[column].sum()) + \" - \" + str((ml_dataset[column].sum() / ml_dataset[ml_dataset[column] != 0][column].count())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the values above, SpecialReduction can be ignored as there are no non-zero values.\n",
    "\n",
    "SpecialRehabilitation can be ignored as it appears infrequently and contributes little to overall settlement amount (max value £21).\n",
    "\n",
    "SpecialMedication can be ignored as it appears infrequently and contributes little to overall settlement amount (max value £30).\n",
    "\n",
    "Columns with a high maximum value but low mean are candidates for grouping and further analysis is required.\n",
    "\n",
    "SpecialAdditionalInjury, SpecialFixes, SpecialHealthExpenses and SpecialLoanerVehicle could all be relevant groups, as they have low frequency but can be high value.\n",
    "\n",
    "GeneralUplift - there are a small number of high values in this column\n",
    "\n",
    "SpecialTripCosts and SpecialJourneyExpenses may be important - need to perform further analysis\n",
    "\n",
    "\n",
    "Recommend investigating the relationship and correlations between the different types of columns (eg. can medical / trip+journey expenses be grouped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0UiWXMdFI3X",
    "tags": []
   },
   "source": [
    "## Display the first x rows of the dataset using a slider widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(lambda x: ml_dataset.head(x), x=(widgets.IntSlider(min=5, max=50, step=5, value=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvTsLPTIFI3Y",
    "tags": []
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BtuGcuJ2FI3Y",
    "tags": []
   },
   "source": [
    "## Display Null Value Counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK9c2WSBFI3Y",
    "tags": []
   },
   "source": [
    "Null values indicate missing data and impact a feature column's usefulness in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhG8eaOiFI3Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find nulls\n",
    "ml_dataset.isnull()\n",
    "ml_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jHMleM9FI3Y",
    "tags": []
   },
   "source": [
    "## Check for Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6KiPn3lLFI3Y"
   },
   "source": [
    "Duplicate rows contaminate the data and could skew the training process, negatively impacting prediction performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rMGSxitNFI3Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculate duplicates\n",
    "duplicates = ml_dataset.duplicated()\n",
    "# report duplicates\n",
    "print(duplicates.any())\n",
    "# list duplicate rows\n",
    "print(ml_dataset[duplicates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqdu5adyFI3Y",
    "tags": []
   },
   "source": [
    "## Check for Negative Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xo6efGZZFI3Z",
    "tags": []
   },
   "source": [
    "Negative values where they are not expected/possible would also affect the reliability of the analysis and should be removed prior to proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "237rtOiRFI3Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for negative values in all columns of Dataframe\n",
    "for column_name in ml_dataset.columns:\n",
    "    column = ml_dataset[column_name]\n",
    "    # Get the count of negatives in column\n",
    "    count = (column < 0).sum()\n",
    "    print('Count of negative values in column ', column_name, ' is : ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUOQb2wTFI3Z",
    "tags": []
   },
   "source": [
    "## Display count of zero values for all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUc0wT6qFI3Z"
   },
   "source": [
    "Zero values are often used as placeholders for null values, so any row containing a zero value should be validated to determine if it is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTcTM855FI3Z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count number of zeros in all columns of Dataframe\n",
    "for column_name in ml_dataset.columns:\n",
    "    column = ml_dataset[column_name]\n",
    "    # Get the count of Zeros in column\n",
    "    count = (column == 0).sum()\n",
    "    print('Count of zeros in column ', column_name, ' is : ', count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkdzStl2FI3Z",
    "tags": []
   },
   "source": [
    "## Removal of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn7o_LtsFI3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ml_dataset_dropcols = ml_dataset.drop(columns=['Insulin'])\n",
    "# ml_dataset = ml_dataset_dropcols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hLE1VypFI3a"
   },
   "source": [
    "## Impute Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiqzsdiPFI3a",
    "tags": []
   },
   "source": [
    "### Convert zero values to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kb9eTwl2FI3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace zero values with NaN in selected columns\n",
    "# ml_dataset.loc[ml_dataset.Glucose == 0, 'Glucose'] = np.NaN\n",
    "# ml_dataset.loc[ml_dataset.BloodPressure == 0, 'BloodPressure'] = np.NaN\n",
    "# ml_dataset.loc[ml_dataset.SkinThickness == 0, 'SkinThickness'] = np.NaN\n",
    "# ml_dataset.loc[ml_dataset.BMI == 0, 'BMI'] = np.NaN\n",
    "\n",
    "# display describe summary table to confirm the changes\n",
    "ml_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0eCkhu5FFI3a",
    "tags": []
   },
   "source": [
    "### Impute mean average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdEBvOvtFI3a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # replace NaN values with mean value for the SkinThickness column\n",
    "# ml_dataset[\"SkinThickness\"] = ml_dataset[\"SkinThickness\"].fillna((ml_dataset[\"SkinThickness\"].mean())).round(2)\n",
    "\n",
    "# # display column summary to confirm changes\n",
    "# ml_dataset[\"SkinThickness\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0Qpf5tSFI3b",
    "tags": []
   },
   "source": [
    "### Impute using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7_A7hM0FI3b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.impute import KNNImputer\n",
    "\n",
    "# # create a KNN imputer object\n",
    "# imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# # impute missing values using KNN for specified columns\n",
    "# columns = ['Glucose','BloodPressure','BMI']\n",
    "# for col in columns:\n",
    "#     temp_df = pd.DataFrame(ml_dataset[col])\n",
    "#     ml_dataset[col] = pd.DataFrame(imputer.fit_transform(temp_df)).round(2)\n",
    "\n",
    "# ml_dataset.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JI9BB-dFI3b",
    "tags": []
   },
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJeI_Om7FI3b",
    "tags": []
   },
   "source": [
    "### The following section is retained for reference only, as applying outlier removal to the dataset ultimately reduced performance of the trained model. Code relating to inspecting the outliers has been left intact, but all code relating to removal of outlier data has been commented out to prevent it from impacting model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWTIzggcFI3b",
    "tags": []
   },
   "source": [
    "Outlier detection is useful to remove datapoints that may disproportionately affect the model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxNuj1j7FI3b",
    "tags": []
   },
   "source": [
    "### Extreme Value Analysis\n",
    "Calculate the interquartile range (IQR)\n",
    "\n",
    "IQR (Inter quantiles range)= 75th quantile — 25th quantile\n",
    "\n",
    "An outlier will be in the following upper and lower boundaries:\n",
    "- Upper Boundary = 75th quantile +(IQR * 1.5)\n",
    "- Lower Boundary = 25th quantile — (IQR * 1.5)\n",
    "\n",
    "Or for extreme cases:\n",
    "- Upper Boundary = 75th quantile +(IQR * 3)\n",
    "- Lower Boundary = 25th quantile — (IQR * 3)\n",
    "\n",
    "If the data point is above the upper boundary or below the lower boundary, it can be considered as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HuqZBMotFI3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # function to calculate inter-quartile ranges for a given column\n",
    "# def calc_iqr(column):\n",
    "#     temp_df = pd.DataFrame(ml_dataset[column])\n",
    "\n",
    "#     # calculate inter-quartile range\n",
    "#     IQR = (temp_df.quantile(0.75) - temp_df.quantile(0.25)).round(3)\n",
    "\n",
    "#     # Calculate lower limit and lower limit extreme\n",
    "#     lower_limit = (temp_df.quantile(0.25) - (IQR * 1.5)).round(3)\n",
    "#     lower_limit_extreme = (temp_df.quantile(0.25) - (IQR * 3)).round(3)\n",
    "\n",
    "#     # prevent negative numbers being evaluated\n",
    "#     lower_limit[lower_limit < 0] = 0\n",
    "#     lower_limit_extreme[lower_limit_extreme < 0] = 0\n",
    "\n",
    "#     # get lower boundary and lower boundary extreme from the dataframe\n",
    "#     compare_lower = lower_limit.iloc[0]\n",
    "#     compare_lower_ex = lower_limit_extreme.iloc[0]\n",
    "\n",
    "#     # compare the column data with the boundary value\n",
    "#     lower_criteria = temp_df[(temp_df.iloc[:,0]) < compare_lower]\n",
    "#     lower_ex_criteria = temp_df[(temp_df.iloc[:,0]) < compare_lower_ex]\n",
    "\n",
    "#     # Calculate upper limit and upper limit extreme\n",
    "#     upper_limit = (temp_df.quantile(0.75) + (IQR * 1.5)).round(3)\n",
    "#     upper_limit_extreme = (temp_df.quantile(0.75) + (IQR * 3)).round(3)\n",
    "\n",
    "#     # get upper boundary and upper boundary extreme from the dataframe\n",
    "#     compare_upper = upper_limit.iloc[0]\n",
    "#     compare_upper_ex = upper_limit_extreme.iloc[0]\n",
    "\n",
    "#     # compare the column data with the boundary value\n",
    "#     upper_criteria = temp_df[(temp_df.iloc[:,0]) > compare_upper]\n",
    "#     upper_ex_criteria = temp_df[(temp_df.iloc[:,0]) > compare_upper_ex]\n",
    "\n",
    "#     # display results of the calculations\n",
    "#     print('\\nTotal participants:',temp_df.size)\n",
    "#     print(column, 'Inter-Quartile Range (IQR) = ', IQR[0])\n",
    "\n",
    "#     print('\\n', column, 'Lower Limit = ', lower_limit[0])\n",
    "#     print('Participants with', column, 'below Lower Limit:', lower_criteria.size)\n",
    "\n",
    "#     print('\\n', column, 'Lower Limit Extreme = ', lower_limit_extreme[0])\n",
    "#     print('Participants with', column, 'below Lower Limit Extreme:', lower_ex_criteria.size)\n",
    "\n",
    "#     print('\\n', column, 'Upper Limit = ', upper_limit[0])\n",
    "#     print('Participants with', column, 'above Upper Limit:', upper_criteria.size)\n",
    "\n",
    "#     print('\\n', column, 'Upper Limit Extreme = ', upper_limit_extreme[0])\n",
    "#     print('Participants with', column, 'above Upper Limit Extreme:', upper_ex_criteria.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tI6dUFQTFI3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # widget to display IQR values for the column selected in a drop-down box\n",
    "# widgets.interact(lambda column: calc_iqr(column), column=['Age','Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ago1z6MtFI3c",
    "tags": []
   },
   "source": [
    "### Removal of Extreme Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkROUirLFI3c"
   },
   "source": [
    "Remove extreme outliers identified in the previous section\n",
    "\n",
    "*The following code section is commented out to prevent data removal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHN9DYz7FI3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ml_dataset_ex_outs = ml_dataset\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['SkinThickness'] > 53)].index\n",
    "# ml_dataset_ex_outs.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['BMI'] > 63.90)].index\n",
    "# ml_dataset_ex_outs.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['DiabetesPedigreeFunction'] > 1.77375)].index\n",
    "# ml_dataset_ex_outs.drop(index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fmgfDziFI3c",
    "tags": []
   },
   "source": [
    "### Visualizing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKKDVhpJFI3c"
   },
   "source": [
    "Using a box plot is a quick method of visualizing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dQqjBdMSFI3c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # sns.boxplot(y='annual_inc', data = data)\n",
    "# widgets.interact(lambda X: sns.boxplot(data=ml_dataset, x=X), X=['Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction','Age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOtOTsS5FI3d",
    "tags": []
   },
   "source": [
    "### List Outliers Based on Limits Identifed in the Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQzGTk9vFI3d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(ml_dataset[(ml_dataset['SkinThickness'] > 80)].index)\n",
    "# print(ml_dataset[(ml_dataset['Age'] > 65)].index)\n",
    "# print(ml_dataset[(ml_dataset['BMI'] > 50)].index)\n",
    "# print(ml_dataset[(ml_dataset['BloodPressure'] > 105)].index)\n",
    "# print(ml_dataset[(ml_dataset['BloodPressure'] < 40)].index)\n",
    "# print(ml_dataset[(ml_dataset['Pregnancies'] > 13)].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc3PqKHRFI3d",
    "tags": []
   },
   "source": [
    "### Outlier Removal Based on Boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMUPaVRXFI3d"
   },
   "source": [
    "*This section is commented out to prevent data removal*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8R0fD2ZVFI3d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# index = ml_dataset[(ml_dataset['SkinThickness'] > 80)].index\n",
    "# ml_dataset.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['Age'] > 65)].index\n",
    "# ml_dataset.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['BMI'] > 50)].index\n",
    "# ml_dataset.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['BloodPressure'] > 105)].index\n",
    "# ml_dataset.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['BloodPressure'] < 40)].index\n",
    "# ml_dataset.drop(index, inplace=True)\n",
    "\n",
    "# index = ml_dataset[(ml_dataset['Pregnancies'] > 13)].index\n",
    "# ml_dataset.drop(index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbW2gpjYFI3d",
    "tags": []
   },
   "source": [
    "# Initial Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSDV4f-pFI3d",
    "tags": []
   },
   "source": [
    "## Outcome Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiHg4oxWFI3e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.countplot(x=ml_dataset['Settlement'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vbo_G3gFI3e",
    "tags": []
   },
   "source": [
    "## Histogram chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rWsOLy3FI3e"
   },
   "source": [
    "Histogram chart using dropdown widget to allow switching between x values. This allows quick viewing of the recorded frequency of the dataset feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qlUSA9VJFI3e",
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Python311/python.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# widgets.interact(lambda X: ml_dataset[X].plot.hist(bins=10, figsize=(10,5)), X=['Age','Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26PbwP11FI3e",
    "tags": []
   },
   "source": [
    "## Distribution Plot Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jevor2xoFI3e"
   },
   "source": [
    "Distribution Plot chart using dropdown widget to allow switching between x values. This allows comparison of the feature distributions for each outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWoBBa04FI3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# widgets.interact(lambda X: sns.displot(data=ml_dataset, x=X, col='Outcome', kind='kde'), X=['Age','Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trvHi1f0FI3f",
    "tags": []
   },
   "source": [
    "## Scatter Plot Chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYOscKHCFI3f"
   },
   "source": [
    "Scatter Plot chart, using X-axis and Y-axis dropdown widgets to allow bivariate analysis for identifying potential relationships between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MqZrHE-_FI3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# widgets.interact(lambda X, Y: sns.scatterplot(data=ml_dataset, style=ml_dataset['Outcome'], hue=ml_dataset['Outcome'], x=X, y=Y), X=['Age','Pregnancies','Glucose','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction'], Y=['Glucose','Pregnancies','BloodPressure','SkinThickness','BMI','DiabetesPedigreeFunction','Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RC_33bBOFI3f",
    "tags": []
   },
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15etA7AnFI3f"
   },
   "source": [
    "A correlation matrix quantifies and visualizes the linear relationships between variables, aiding in feature selection and understanding variable interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LK34pfcyFI3f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # calculate the feature correlation values\n",
    "# c = ml_dataset.select_dtypes('number').corr().round(3)\n",
    "\n",
    "# # Plot the correlation matrix as a heatmap\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.heatmap(c, annot=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABth0byzFI3g",
    "tags": []
   },
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4C6jJmRuFI3g"
   },
   "source": [
    "As a final data processing step, we will apply recursive feature elimination with cross validation (RFECV) to identify the most useful features on which to train the models. Reducing the dimensionality and overall size of the dataset decreases training time and improves efficiency, which both contribute to a lower financial costs through reduced compute requirements and reduction in energy consumption, resulting in a more sustainable approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hI7adw3gFI3g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import required library functions\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # split dataset to features and classifications\n",
    "# X = ml_dataset.drop([\"Outcome\"], axis = 1)\n",
    "# y = ml_dataset[\"Outcome\"]\n",
    "\n",
    "# # use a linear regressino model for cross validation testing\n",
    "# regressor = LinearRegression()\n",
    "# feature_selector = RFECV(regressor)\n",
    "\n",
    "# # train the model\n",
    "# fit = feature_selector.fit(X,y)\n",
    "\n",
    "# # determine and print result of feature evaluation\n",
    "# optimal_feature_count = feature_selector.n_features_\n",
    "# print(f\"Optimal numer of features: {optimal_feature_count}\")\n",
    "\n",
    "# print(X.columns)\n",
    "# print(feature_selector.ranking_)\n",
    "# print(feature_selector.support_)\n",
    "\n",
    "# # plot chart of evaluation runs\n",
    "# plt.plot(range(1, len(fit.grid_scores_) + 1), fit.grid_scores_, marker = \"o\")\n",
    "# plt.ylabel(\"Model Score\")\n",
    "# plt.xlabel(\"Number of Features\")\n",
    "# plt.title(f\"Feature Selection using RFE\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jExPYh7HFI3g"
   },
   "source": [
    "### Removal of features recommended by the RFECV process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd-jbQRCFI3g",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # drop specificed columns to a new dataframe\n",
    "# ml_dataset_4col = ml_dataset.drop(['BloodPressure', 'SkinThickness','Age'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eswTCThAFI3g",
    "tags": []
   },
   "source": [
    "# Model 1: Baseline for Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-z0gWrcFI3h",
    "tags": []
   },
   "source": [
    "## Split Features and Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83Y0ewmaFI3h"
   },
   "source": [
    "Split the dataset into two ndarrays, one for the feature matrix and another for the corresponding classifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gQ0P3IaTFI3h"
   },
   "outputs": [],
   "source": [
    "# # Create X for features\n",
    "# X=df.drop(['Settlement'],axis=1)\n",
    "\n",
    "# # Create y for classes\n",
    "# y=df['Settlement']\n",
    "\n",
    "# # Display first 5 rows of X\n",
    "# X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AV2JicvFI3h",
    "tags": []
   },
   "source": [
    "## Divide Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5M480npjFI3h"
   },
   "source": [
    "Split the dataset to utilise 70% of the data for training and 30% for testing. The model training was repeated with an 80:20 split (the usual recommendation) and with a 90:10 split, but the 70:30 ratio outperformed both of those options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxXImL7CFI3h",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1)\n",
    "\n",
    "# print('Training dataframes have shape:', X_train.shape, y_train.shape, '\\nTest dataframes have shape:',X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42iC4nUCFI3h",
    "tags": []
   },
   "source": [
    "## Stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3VT9eRcFI3i"
   },
   "outputs": [],
   "source": [
    "## split dataframe using stratification\n",
    "# train, test = train_test_split(ml_dataset_4col, test_size=0.3, random_state=1, stratify=ml_dataset_4col['Outcome'])\n",
    "\n",
    "## split stratified training data into features and classes\n",
    "# X_train=train.drop(['Outcome'],axis=1)\n",
    "# y_train=train['Outcome']\n",
    "\n",
    "## split stratified test data into features and classes\n",
    "# X_test=test.drop(['Outcome'],axis=1)\n",
    "# y_test=test['Outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6rnzzlFFI3i",
    "tags": []
   },
   "source": [
    "## Display Train and Test dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJnpn7HrFI3i"
   },
   "source": [
    "Use dropdown menu to display initial records for selected dataframe - choose between features (X) and classes (y) for either train or test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ht1y4pXLFI3i"
   },
   "outputs": [],
   "source": [
    "# def display_head(display):\n",
    "#     if display == 'X_train':\n",
    "#         print(X_train.head(5))\n",
    "\n",
    "#     if display == 'X_test':\n",
    "#         print(X_test.head(5))\n",
    "\n",
    "#     if display == 'y_train':\n",
    "#         print(y_train.head(5))\n",
    "\n",
    "#     if display == 'y_test':\n",
    "#         print(y_test.head(5))\n",
    "\n",
    "# widgets.interact(lambda Selection: display_head(Selection), Selection=['X_train', 'y_train', 'X_test', 'y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiE_4kuFFI3i",
    "tags": []
   },
   "source": [
    "## Create Processing and Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SQ4dukPFI3i",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Import libraries required for SVM model, pipeline and scaling\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.svm import SVC\n",
    "\n",
    "# # create pipeline to scale features\n",
    "# default_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svm', SVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-ByZP2kFI3i",
    "tags": []
   },
   "source": [
    "## Train Default Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 1681,
     "status": "error",
     "timestamp": 1716263736188,
     "user": {
      "displayName": "Bradley Booth",
      "userId": "10896882746436852839"
     },
     "user_tz": -480
    },
    "id": "jqITdZlXFI3j",
    "outputId": "1a1c0ca2-3fd3-44e0-ea10-89d2d20299b1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c7bc2b4643f6>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# train default model using the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdefault_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# make predictions based on the default model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# # import libraries required for reporting\n",
    "# from sklearn import metrics\n",
    "\n",
    "# # train default model using the pipeline\n",
    "# default_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions based on the default model\n",
    "# y_pred_def = default_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4MHVPRjFI3l",
    "tags": []
   },
   "source": [
    "## Performance Metrics Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "InJBwUhiFI3l"
   },
   "source": [
    "As we will be re-using these performance metrics throughout the notebook, it makes sense to create a function that can be called as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tVpoACapFI3l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # import library functions\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# def display_metrics(y_test,y_pred):\n",
    "#     # generate and display confusion matrix\n",
    "#     conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "#     plot_confusion_matrix(conf_matrix)\n",
    "\n",
    "#     # display classification report\n",
    "#     print(classification_report(y_test,y_pred))\n",
    "\n",
    "#     # display f1 score\n",
    "#     print('F1 Score:', f1_score(y_test,y_pred))\n",
    "\n",
    "#     # display roc-auc score\n",
    "#     print('ROC-AUC Score:', roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vu06vbDPFI3l",
    "tags": []
   },
   "source": [
    "## Default Model Performance Metrics Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1K27iTNFI3l"
   },
   "source": [
    "To demonstrate the complete metrics report, it is now applied to the default model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOqGOsK3FI3l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # display metrics using previously defined function\n",
    "# display_metrics(y_test,y_pred_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anGC9tqbFI3l",
    "tags": []
   },
   "source": [
    "## Apply Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yRYAEtSFI3m",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # create weighted pipeline to scale features\n",
    "# weighted_pipe = Pipeline(steps=[('scaler', StandardScaler()), ('svm', SVC(class_weight='balanced'))])\n",
    "\n",
    "# # train model using the weighted pipeline\n",
    "# weighted_pipe.fit(X_train, y_train)\n",
    "\n",
    "# # make predictions based on the weighted model\n",
    "# y_pred_weighted = weighted_pipe.predict(X_test)\n",
    "\n",
    "# # display metrics using previously defined function\n",
    "# display_metrics(y_test,y_pred_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P77VPzOFI3r",
    "tags": []
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HxcQy_rFI3r"
   },
   "source": [
    "Rather than just training the model once on the entire training dataset, cross validation partitions the data into multiple subsets, training the model on some subsets and validating it on others, and then averaging the results to better estimate its performance on unseen data, resulting in a more generalized model with reduced tendency to overfit.\n",
    "\n",
    "The sklearn RepeatedStratifiedKFold function is a cross-validation method that implements stratification of the training and validation partitions during cross validation. It achieves this by repeatedly splitting the dataset into 'K' stratified folds, ensuring that each fold is a good representative of the whole, and it is used multiple times to provide a more robust estimate of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXrTn8s2FI3r",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # importing libraries and functions needed for cross validation\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# # define reusable cross validation test harness\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
